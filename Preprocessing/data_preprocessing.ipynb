{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete for 211 files!\n"
     ]
    }
   ],
   "source": [
    "data_directory = '../db/raw/dbdc4_en_dev_labeled'\n",
    "\n",
    "file_list = os.listdir(data_directory)\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No files found in the data directory!\")\n",
    "\n",
    "file_count = 0\n",
    "for file_name in file_list:\n",
    "    file_count += 1\n",
    "    if file_name.endswith('.json'):\n",
    "        file_path = os.path.join(data_directory, file_name)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        for turn in data.get(\"turns\", []):\n",
    "            turn.pop(\"time\", None)\n",
    "            turn.pop(\"annotation-id\", None)\n",
    "            for annotation in turn.get(\"annotations\", []):\n",
    "                annotation.pop(\"comment\", None)\n",
    "                annotation.pop(\"annotator-id\", None)\n",
    "                annotation.pop(\"ungrammatical-sentence\", None)\n",
    "        \n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Data cleaning complete for {file_count} files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Majority Voting Function and Probability Distribution\n",
    "##### Treat Breakdown and Possible Breakdown as Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete for 211 files!\n"
     ]
    }
   ],
   "source": [
    "def interpret_breakdown(annotation):\n",
    "    return \"breakdown\" if annotation['breakdown'] in ['X', 'T'] else \"non-breakdown\"\n",
    "\n",
    "file_count = 0\n",
    "data_directory = '../db/raw/dbdc4_en_dev_labeled'\n",
    "file_list = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No JSON files found in the directory.\")\n",
    "else:\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        for turn in data[\"turns\"]:\n",
    "\n",
    "            annotations_interpreted = [interpret_breakdown(annotation) for annotation in turn.get(\"annotations\", [])]\n",
    "\n",
    "            # Calculate the majority voting\n",
    "            majority_vote = Counter(annotations_interpreted).most_common(1)[0][0] if annotations_interpreted else None\n",
    "\n",
    "            # Calculate probability distribution\n",
    "            total_annotations = len(annotations_interpreted) if annotations_interpreted else 1\n",
    "            probability_distribution = {\n",
    "                \"breakdown\": annotations_interpreted.count(\"breakdown\") / total_annotations,\n",
    "                \"non-breakdown\": annotations_interpreted.count(\"non-breakdown\") / total_annotations\n",
    "            }\n",
    "            turn[\"majority_voting\"] = majority_vote\n",
    "            turn[\"probability_distribution\"] = probability_distribution\n",
    "\n",
    "        file_count += 1\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    print(f\"Data processing complete for {file_count} files!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed majority voting and probability distribution from first utterances or user dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Further data cleaning complete for 211 files!\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "data_directory = '../db/raw/dbdc4_en_dev_labeled'\n",
    "file_list = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No JSON files found in the directory.\")\n",
    "else:\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        for turn in data[\"turns\"]:\n",
    "\n",
    "            if turn[\"speaker\"] == \"U\" or turn[\"turn-index\"] == 0:\n",
    "                turn.pop(\"majority_voting\", None)\n",
    "                turn.pop(\"probability_distribution\", None)\n",
    "        file_count += 1\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "    print(f\"Further data cleaning complete for {file_count} files!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Cleaned CSV Files for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 211 JSON files to CSV in the '../db/raw/dbdc4_en_dev_labeled/csv' directory.\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "\n",
    "data_directory = '../db/raw/dbdc4_en_dev_labeled'\n",
    "output_directory = '../db/raw/dbdc4_en_dev_labeled/csv'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "file_list = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No JSON files found in the directory.\")\n",
    "else:\n",
    "    for file_name in file_list:\n",
    "        json_file_path = os.path.join(data_directory, file_name)\n",
    "        csv_file_path = os.path.join(output_directory, os.path.splitext(file_name)[0] + '.csv')\n",
    "\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(['Speaker', 'Utterance'])\n",
    "                for turn in data[\"turns\"]:\n",
    "                    speaker = turn[\"speaker\"]\n",
    "                    utterance = turn[\"utterance\"].replace('\\n', ' ').strip()\n",
    "                    \n",
    "                    writer.writerow([speaker, utterance])\n",
    "            \n",
    "            file_count += 1\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "\n",
    "    print(f\"Converted {file_count} JSON files to CSV in the '{output_directory}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further cleaning with labelled output (ensures we have user/bot utterances, majority voting and prob distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 211 JSON files to CSV in the '../db/raw/dbdc4_en_dev_labeled/output' directory.\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "data_directory = '../db/raw/dbdc4_en_dev_labeled'\n",
    "output_directory = '../db/raw/dbdc4_en_dev_labeled/output'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "file_list = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No JSON files found in the directory.\")\n",
    "else:\n",
    "    for file_name in file_list:\n",
    "        json_file_path = os.path.join(data_directory, file_name)\n",
    "        csv_file_path = os.path.join(output_directory, os.path.splitext(file_name)[0] + '.csv')\n",
    "\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(['Speaker', 'Utterance', 'Majority Voting', 'Probability Distribution'])\n",
    "                for turn in data[\"turns\"]:\n",
    "                    speaker = turn[\"speaker\"]\n",
    "                    utterance = turn[\"utterance\"].replace('\\n', ' ').strip()\n",
    "\n",
    "                    # Initialize majority_voting and formatted_probability as empty strings\n",
    "                    majority_voting = ''\n",
    "                    formatted_probability = ''\n",
    "\n",
    "                    # Check if 'majority_voting' and 'probability_distribution' exist in the turn\n",
    "                    if 'majority_voting' in turn and 'probability_distribution' in turn:\n",
    "                        majority_voting = turn[\"majority_voting\"]\n",
    "                        probability_distribution = turn[\"probability_distribution\"]\n",
    "\n",
    "                        # Get the probability for the majority_voting value\n",
    "                        majority_voting_probability = probability_distribution.get(majority_voting, 0)\n",
    "                        formatted_probability = f\"{majority_voting_probability:.1f}\"\n",
    "\n",
    "                    writer.writerow([speaker, utterance, majority_voting, formatted_probability])\n",
    "                    \n",
    "            file_count += 1\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "\n",
    "    print(f\"Converted {file_count} JSON files to CSV in the '{output_directory}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Files for LLM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to format each utterance by adding a line number and user / bot header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dialogue(json_data, file_path):\n",
    "    dialogue = \"\"\n",
    "    \n",
    "    line_number = 1\n",
    "    for turn in json_data['turns']:\n",
    "        turn['utterance'] = turn[\"utterance\"].replace('\\n', ' ').strip()\n",
    "        \n",
    "        if turn['speaker'] == 'S':\n",
    "            dialogue += f\"{line_number}. Bot: {turn['utterance']}\\n\"\n",
    "        else:\n",
    "            dialogue += f\"{line_number}. User: {turn['utterance']}\\n\"\n",
    "\n",
    "        line_number += 1\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(dialogue)\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0\n",
    "\n",
    "data_directory = '../db/raw/dbdc4_en_dev_labeled/'\n",
    "output_directory = '../db/raw/dev/text_eval'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "file_list = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "if not file_list:\n",
    "    print(\"No JSON files found in the directory.\")\n",
    "else:\n",
    "    for file_name in file_list:\n",
    "        json_file_path = os.path.join(data_directory, file_name)\n",
    "        text_path = os.path.join(output_directory, os.path.splitext(file_name)[0] + '.txt')\n",
    "\n",
    "        try:\n",
    "            with open(json_file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            convert_to_dialogue(data, text_path)\n",
    "            \n",
    "            file_count += 1\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
    "\n",
    "    print(f\"Converted {file_count} JSON files to Text in the '{output_directory}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used to Automate LLM response analysis\n",
    "Labelled cleaning to match similar context to utterances to segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def transform_dialogue(file_path, output_folder):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Speaker'] = df['Speaker'].map({'S': 'Bot', 'U': 'User'})\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df.at[i, 'Utterance'] = f\"{i+1}. {df.at[i, 'Speaker']}: {df.at[i, 'Utterance']}\"\n",
    "\n",
    "    df.drop(columns=['Speaker'], inplace=True)\n",
    "\n",
    "    df['Utterance'] = df['Utterance'].str.replace('\"', \"'\", regex=False)\n",
    "    df['Utterance'] = df['Utterance'].str.replace('\\n', ' ', regex=True)\n",
    "    df['Utterance'] = df['Utterance'].str.replace(',', ';', regex=False)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    output_file_path = os.path.join(output_folder, f\"{base_name}.csv\")\n",
    "\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "input_dir = '../db/raw/dbdc4_en_dev_labeled/output'\n",
    "output_dir = '../db/raw/dev_labelled'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file_path in glob.glob(f\"{input_dir}/*.csv\"):\n",
    "    transform_dialogue(file_path, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEC475",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
